As stated by the authors of **The AeroScapes Semantic Segmentation** dataset, they explore methods for learning across train and test distributions that dramatically differ in scene structure, viewpoints, and objects statistics. Authors motivated by the proliferation of aerial drone robotics, and consider the target task of semantic segmentation from aerial viewpoints. Inspired by the impact of Cityscapes, authors introduce AeroScapes, a new dataset of 3269 images of aerial scenes (captured with a fleet of drones) annotated with dense semantic segmentations. This dataset differs from existing segmentation datasets (that focus on ground-view or indoor scene domains) in terms of viewpoint, scene composition, and object scales. Authors propose a simple but effective approach for transferring knowledge from such diverse do mains (for which considerable annotated training data exists) to target task. To do so, authors train multiple models for aerial segmentation via progressive fine-tuning through each source domain. They then treat these collections of models as an ensemble that can be aggregated to significantly improve performance. Authors demonstrate large absolute im provements (8.12%) over widely-used standard baselines.
